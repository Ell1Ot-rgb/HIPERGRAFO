# üöÄ MAXIMIZANDO EL ENTRENAMIENTO EN CPU (DOCKER)

Dado que tu entorno de Codespaces tiene **2 n√∫cleos (cores)** disponibles, hemos aplicado una serie de optimizaciones de bajo nivel para exprimir cada ciclo de reloj sin saturar el sistema.

## üõ†Ô∏è Optimizaciones Aplicadas

### 1. Gesti√≥n de Hilos (Threading)
En CPUs con pocos n√∫cleos, el mayor enemigo es el "Context Switching" (cuando el procesador pierde tiempo saltando entre demasiados hilos).
- **Configuraci√≥n:** Hemos limitado PyTorch y OpenMP a exactamente **2 hilos** (`OMP_NUM_THREADS=2`).
- **Resultado:** El procesador se mantiene enfocado en el c√°lculo matricial sin distracciones.

### 2. Aceleraci√≥n OneDNN (MKL-DNN)
Hemos habilitado el backend de **OneDNN** en el Dockerfile.
- **¬øQu√© hace?:** Utiliza instrucciones vectoriales avanzadas de tu CPU AMD EPYC (como **AVX2** y **FMA**) para acelerar las multiplicaciones de matrices.
- **Configuraci√≥n:** `TORCH_CPU_BACKEND=onednn`.

### 3. Bibliotecas de √Ålgebra Lineal
Hemos cambiado las librer√≠as est√°ndar por **OpenBLAS** y **libomp**, que est√°n mejor optimizadas para arquitecturas Linux modernas.

### 4. L√≠mites de Recursos en Docker
El archivo `docker-compose.yml` ahora tiene reservas y l√≠mites estrictos:
- **CPUs:** 2.0 (Uso total de los n√∫cleos disponibles).
- **Memoria:** Reserva de 1GB, l√≠mite de 4GB.

---

## üìà Consejos para mejorar la velocidad en 2 Cores

Si sientes que el entrenamiento sigue siendo lento, aplica estos cambios en tu l√≥gica de entrenamiento:

1.  **Batch Size Peque√±o:** Usa un batch size de **8 o 16**. Esto permite que los datos quepan en la memoria cach√© (L2/L3) del procesador, que es miles de veces m√°s r√°pida que la RAM.
2.  **Num Workers = 0:** En tus `DataLoaders` de PyTorch, establece `num_workers=0`. En sistemas de 2 n√∫cleos, crear procesos adicionales para cargar datos suele ser m√°s lento que cargarlos en el proceso principal.
3.  **Precisi√≥n Simple (Float32):** No intentes usar Double (Float64). Float32 es el "punto dulce" para CPUs con AVX2.

---

## üõ†Ô∏è C√≥mo aplicar los cambios

Si ya hab√≠as construido la imagen antes, debes reconstruirla para aplicar las nuevas optimizaciones:

```bash
# Detener y borrar lo anterior
docker stop omega21_local_trainer
docker rm omega21_local_trainer

# Reconstruir con las optimizaciones de CPU
./scripts/run_docker_training.sh
```

Puedes verificar que las optimizaciones est√°n activas viendo los logs:
```bash
docker logs omega21_local_trainer
```
Deber√≠as ver: `üíª MODO LOCAL: Usando cpu con 2 hilos`.
