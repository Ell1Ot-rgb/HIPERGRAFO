# üè† ENTRENAMIENTO LOCAL EN VS CODE

## An√°lisis de Viabilidad

¬øEs posible entrenar OMEGA 21 directamente en este entorno (VS Code/Codespaces)?
**S√ç, es posible, pero con limitaciones importantes.**

### üìä Comparativa: Local (VS Code) vs. Remoto (Colab)

| Caracter√≠stica | üè† VS Code Local (CPU) | ‚òÅÔ∏è Google Colab (GPU) |
|----------------|------------------------|-----------------------|
| **Velocidad** | Lenta (x1) | Muy R√°pida (x50 - x100) |
| **Hardware** | CPU (AMD EPYC 64-Core) | GPU (NVIDIA T4/A100) |
| **RAM** | ~8 GB (Compartida) | ~12-25 GB (Dedicada) |
| **Uso Ideal** | Depuraci√≥n, Pruebas, Datasets peque√±os | Entrenamiento masivo, Datasets grandes |
| **Persistencia**| Alta (Archivos se guardan) | Baja (Se borra al cerrar) |

### üõ†Ô∏è Estrategia H√≠brida (Recomendada)

1.  **Desarrollo y Pruebas (AQU√ç):** Usa el servidor local para verificar que tu c√≥digo funciona, probar la arquitectura y entrenar con pocos datos (ej: 100 muestras).
2.  **Entrenamiento Pesado (COLAB):** Cuando todo funcione, cambia la URL a Colab para entrenar con miles de datos.

---

## üöÄ C√≥mo usar el Servidor Local

He creado una versi√≥n optimizada para CPU del servidor (`src/local_server/servidor_local.py`).

### 1. Instalar dependencias
```bash
pip install fastapi uvicorn psutil torch
```

### 2. Iniciar el servidor
Abre una terminal y ejecuta:
```bash
python3 src/local_server/servidor_local.py
```
Ver√°s:
```
üè† SERVIDOR LOCAL OMEGA 21 - INICIANDO
   ‚Ä¢ URL: http://localhost:8000
   ‚Ä¢ CPU: 64 cores
```

### 3. Configurar el Cliente
En otra terminal, configura la variable de entorno para apuntar a `localhost`:

```bash
export COLAB_SERVER_URL=http://localhost:8000
```

### 4. Ejecutar el entrenamiento
Ahora ejecuta el mismo script de cliente que ya ten√≠as:

```bash
npx ts-node src/colab/ejemplo_entrenamiento_colab.ts
```

---

## ‚ö†Ô∏è Optimizaciones Realizadas (Versi√≥n CPU)

Para que funcione fluido en VS Code, he modificado el modelo en `servidor_local.py`:
1.  **Reducci√≥n de Capas:** LSTM y Transformer tienen menos capas (1 en vez de 2).
2.  **Menos Neuronas:** Capas densas reducidas (1024 en vez de 4096).
3.  **Sin CUDA:** Forzado a usar `device='cpu'`.
4.  **Monitor de RAM:** El servidor rechazar√° peticiones si la RAM supera el 90% para evitar que se cuelgue el entorno.
